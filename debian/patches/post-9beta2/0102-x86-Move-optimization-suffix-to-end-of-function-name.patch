From c37322e68c528717930575ed55fc0e819a8ee215 Mon Sep 17 00:00:00 2001
From: Diego Biurrun <diego@biurrun.de>
Date: Fri, 27 Jul 2012 14:09:52 +0200
Subject: [PATCH 102/278] x86: Move optimization suffix to end of function
 names

This simplifies cpuflags porting.
---
 libavcodec/x86/dsputil_mmx.c     |   20 ++++++++++----------
 libavcodec/x86/h264_chromamc.asm |   20 ++++++++++----------
 libavcodec/x86/vc1dsp_init.c     |   20 ++++++++++----------
 3 files changed, 30 insertions(+), 30 deletions(-)

diff --git a/libavcodec/x86/dsputil_mmx.c b/libavcodec/x86/dsputil_mmx.c
index d23279b..74559f4 100644
--- a/libavcodec/x86/dsputil_mmx.c
+++ b/libavcodec/x86/dsputil_mmx.c
@@ -2043,11 +2043,11 @@ PREFETCH(prefetch_3dnow, prefetch)
 
 #include "h264_qpel.c"
 
-void ff_put_h264_chroma_mc8_mmx_rnd  (uint8_t *dst, uint8_t *src,
+void ff_put_h264_chroma_mc8_rnd_mmx  (uint8_t *dst, uint8_t *src,
                                       int stride, int h, int x, int y);
-void ff_avg_h264_chroma_mc8_mmx2_rnd (uint8_t *dst, uint8_t *src,
+void ff_avg_h264_chroma_mc8_rnd_mmx2 (uint8_t *dst, uint8_t *src,
                                       int stride, int h, int x, int y);
-void ff_avg_h264_chroma_mc8_3dnow_rnd(uint8_t *dst, uint8_t *src,
+void ff_avg_h264_chroma_mc8_rnd_3dnow(uint8_t *dst, uint8_t *src,
                                       int stride, int h, int x, int y);
 
 void ff_put_h264_chroma_mc4_mmx      (uint8_t *dst, uint8_t *src,
@@ -2062,12 +2062,12 @@ void ff_put_h264_chroma_mc2_mmx2     (uint8_t *dst, uint8_t *src,
 void ff_avg_h264_chroma_mc2_mmx2     (uint8_t *dst, uint8_t *src,
                                       int stride, int h, int x, int y);
 
-void ff_put_h264_chroma_mc8_ssse3_rnd(uint8_t *dst, uint8_t *src,
+void ff_put_h264_chroma_mc8_rnd_ssse3(uint8_t *dst, uint8_t *src,
                                       int stride, int h, int x, int y);
 void ff_put_h264_chroma_mc4_ssse3    (uint8_t *dst, uint8_t *src,
                                       int stride, int h, int x, int y);
 
-void ff_avg_h264_chroma_mc8_ssse3_rnd(uint8_t *dst, uint8_t *src,
+void ff_avg_h264_chroma_mc8_rnd_ssse3(uint8_t *dst, uint8_t *src,
                                       int stride, int h, int x, int y);
 void ff_avg_h264_chroma_mc4_ssse3    (uint8_t *dst, uint8_t *src,
                                       int stride, int h, int x, int y);
@@ -2447,7 +2447,7 @@ static void dsputil_init_mmx(DSPContext *c, AVCodecContext *avctx, int mm_flags)
 #endif
 
     if (!high_bit_depth && CONFIG_H264CHROMA) {
-        c->put_h264_chroma_pixels_tab[0] = ff_put_h264_chroma_mc8_mmx_rnd;
+        c->put_h264_chroma_pixels_tab[0] = ff_put_h264_chroma_mc8_rnd_mmx;
         c->put_h264_chroma_pixels_tab[1] = ff_put_h264_chroma_mc4_mmx;
     }
 
@@ -2548,7 +2548,7 @@ static void dsputil_init_mmxext(DSPContext *c, AVCodecContext *avctx,
 
 #if HAVE_YASM
     if (!high_bit_depth && CONFIG_H264CHROMA) {
-        c->avg_h264_chroma_pixels_tab[0] = ff_avg_h264_chroma_mc8_mmx2_rnd;
+        c->avg_h264_chroma_pixels_tab[0] = ff_avg_h264_chroma_mc8_rnd_mmx2;
         c->avg_h264_chroma_pixels_tab[1] = ff_avg_h264_chroma_mc4_mmx2;
         c->avg_h264_chroma_pixels_tab[2] = ff_avg_h264_chroma_mc2_mmx2;
         c->put_h264_chroma_pixels_tab[2] = ff_put_h264_chroma_mc2_mmx2;
@@ -2643,7 +2643,7 @@ static void dsputil_init_3dnow(DSPContext *c, AVCodecContext *avctx,
 
 #if HAVE_YASM
     if (!high_bit_depth && CONFIG_H264CHROMA) {
-        c->avg_h264_chroma_pixels_tab[0] = ff_avg_h264_chroma_mc8_3dnow_rnd;
+        c->avg_h264_chroma_pixels_tab[0] = ff_avg_h264_chroma_mc8_rnd_3dnow;
         c->avg_h264_chroma_pixels_tab[1] = ff_avg_h264_chroma_mc4_3dnow;
     }
 #endif /* HAVE_YASM */
@@ -2796,8 +2796,8 @@ static void dsputil_init_ssse3(DSPContext *c, AVCodecContext *avctx,
         H264_QPEL_FUNCS_10(3, 0, ssse3_cache64);
     }
     if (!high_bit_depth && CONFIG_H264CHROMA) {
-        c->put_h264_chroma_pixels_tab[0] = ff_put_h264_chroma_mc8_ssse3_rnd;
-        c->avg_h264_chroma_pixels_tab[0] = ff_avg_h264_chroma_mc8_ssse3_rnd;
+        c->put_h264_chroma_pixels_tab[0] = ff_put_h264_chroma_mc8_rnd_ssse3;
+        c->avg_h264_chroma_pixels_tab[0] = ff_avg_h264_chroma_mc8_rnd_ssse3;
         c->put_h264_chroma_pixels_tab[1] = ff_put_h264_chroma_mc4_ssse3;
         c->avg_h264_chroma_pixels_tab[1] = ff_avg_h264_chroma_mc4_ssse3;
     }
diff --git a/libavcodec/x86/h264_chromamc.asm b/libavcodec/x86/h264_chromamc.asm
index e3aff0b..dc427d7 100644
--- a/libavcodec/x86/h264_chromamc.asm
+++ b/libavcodec/x86/h264_chromamc.asm
@@ -437,8 +437,8 @@ cglobal %1_%2_chroma_mc2_%3, 6, 7, 0
 INIT_MMX
 %define CHROMAMC_AVG  NOTHING
 %define CHROMAMC_AVG4 NOTHING
-chroma_mc8_mmx_func put, h264, mmx_rnd
-chroma_mc8_mmx_func put, vc1,  mmx_nornd
+chroma_mc8_mmx_func put, h264, rnd_mmx
+chroma_mc8_mmx_func put, vc1,  nornd_mmx
 chroma_mc8_mmx_func put, rv40, mmx
 chroma_mc4_mmx_func put, h264, mmx
 chroma_mc4_mmx_func put, rv40, mmx
@@ -447,16 +447,16 @@ chroma_mc2_mmx_func put, h264, mmx2
 %define CHROMAMC_AVG  DIRECT_AVG
 %define CHROMAMC_AVG4 COPY_AVG
 %define PAVG          pavgb
-chroma_mc8_mmx_func avg, h264, mmx2_rnd
-chroma_mc8_mmx_func avg, vc1,  mmx2_nornd
+chroma_mc8_mmx_func avg, h264, rnd_mmx2
+chroma_mc8_mmx_func avg, vc1,  nornd_mmx2
 chroma_mc8_mmx_func avg, rv40, mmx2
 chroma_mc4_mmx_func avg, h264, mmx2
 chroma_mc4_mmx_func avg, rv40, mmx2
 chroma_mc2_mmx_func avg, h264, mmx2
 
 %define PAVG          pavgusb
-chroma_mc8_mmx_func avg, h264, 3dnow_rnd
-chroma_mc8_mmx_func avg, vc1,  3dnow_nornd
+chroma_mc8_mmx_func avg, h264, rnd_3dnow
+chroma_mc8_mmx_func avg, vc1,  nornd_3dnow
 chroma_mc8_mmx_func avg, rv40, 3dnow
 chroma_mc4_mmx_func avg, h264, 3dnow
 chroma_mc4_mmx_func avg, rv40, 3dnow
@@ -664,15 +664,15 @@ cglobal %1_%2_chroma_mc4_%3, 6, 7, 0
 
 %define CHROMAMC_AVG NOTHING
 INIT_XMM
-chroma_mc8_ssse3_func put, h264, ssse3_rnd
-chroma_mc8_ssse3_func put, vc1,  ssse3_nornd
+chroma_mc8_ssse3_func put, h264, rnd_ssse3
+chroma_mc8_ssse3_func put, vc1,  nornd_ssse3
 INIT_MMX
 chroma_mc4_ssse3_func put, h264, ssse3
 
 %define CHROMAMC_AVG DIRECT_AVG
 %define PAVG         pavgb
 INIT_XMM
-chroma_mc8_ssse3_func avg, h264, ssse3_rnd
-chroma_mc8_ssse3_func avg, vc1,  ssse3_nornd
+chroma_mc8_ssse3_func avg, h264, rnd_ssse3
+chroma_mc8_ssse3_func avg, vc1,  nornd_ssse3
 INIT_MMX
 chroma_mc4_ssse3_func avg, h264, ssse3
diff --git a/libavcodec/x86/vc1dsp_init.c b/libavcodec/x86/vc1dsp_init.c
index d2548fc..6d868e8 100644
--- a/libavcodec/x86/vc1dsp_init.c
+++ b/libavcodec/x86/vc1dsp_init.c
@@ -62,15 +62,15 @@ static void vc1_h_loop_filter16_sse4(uint8_t *src, int stride, int pq)
 }
 #endif /* HAVE_YASM */
 
-void ff_put_vc1_chroma_mc8_mmx_nornd  (uint8_t *dst, uint8_t *src,
+void ff_put_vc1_chroma_mc8_nornd_mmx  (uint8_t *dst, uint8_t *src,
                                        int stride, int h, int x, int y);
-void ff_avg_vc1_chroma_mc8_mmx2_nornd (uint8_t *dst, uint8_t *src,
+void ff_avg_vc1_chroma_mc8_nornd_mmx2 (uint8_t *dst, uint8_t *src,
                                        int stride, int h, int x, int y);
-void ff_avg_vc1_chroma_mc8_3dnow_nornd(uint8_t *dst, uint8_t *src,
+void ff_avg_vc1_chroma_mc8_nornd_3dnow(uint8_t *dst, uint8_t *src,
                                        int stride, int h, int x, int y);
-void ff_put_vc1_chroma_mc8_ssse3_nornd(uint8_t *dst, uint8_t *src,
+void ff_put_vc1_chroma_mc8_nornd_ssse3(uint8_t *dst, uint8_t *src,
                                        int stride, int h, int x, int y);
-void ff_avg_vc1_chroma_mc8_ssse3_nornd(uint8_t *dst, uint8_t *src,
+void ff_avg_vc1_chroma_mc8_nornd_ssse3(uint8_t *dst, uint8_t *src,
                                        int stride, int h, int x, int y);
 
 
@@ -94,14 +94,14 @@ av_cold void ff_vc1dsp_init_x86(VC1DSPContext *dsp)
 
 #if HAVE_YASM
     if (mm_flags & AV_CPU_FLAG_MMX) {
-        dsp->put_no_rnd_vc1_chroma_pixels_tab[0]= ff_put_vc1_chroma_mc8_mmx_nornd;
+        dsp->put_no_rnd_vc1_chroma_pixels_tab[0] = ff_put_vc1_chroma_mc8_nornd_mmx;
     }
 
     if (mm_flags & AV_CPU_FLAG_MMXEXT) {
         ASSIGN_LF(mmx2);
-        dsp->avg_no_rnd_vc1_chroma_pixels_tab[0]= ff_avg_vc1_chroma_mc8_mmx2_nornd;
+        dsp->avg_no_rnd_vc1_chroma_pixels_tab[0] = ff_avg_vc1_chroma_mc8_nornd_mmx2;
     } else if (mm_flags & AV_CPU_FLAG_3DNOW) {
-        dsp->avg_no_rnd_vc1_chroma_pixels_tab[0]= ff_avg_vc1_chroma_mc8_3dnow_nornd;
+        dsp->avg_no_rnd_vc1_chroma_pixels_tab[0] = ff_avg_vc1_chroma_mc8_nornd_3dnow;
     }
 
     if (mm_flags & AV_CPU_FLAG_SSE2) {
@@ -112,8 +112,8 @@ av_cold void ff_vc1dsp_init_x86(VC1DSPContext *dsp)
     }
     if (mm_flags & AV_CPU_FLAG_SSSE3) {
         ASSIGN_LF(ssse3);
-        dsp->put_no_rnd_vc1_chroma_pixels_tab[0]= ff_put_vc1_chroma_mc8_ssse3_nornd;
-        dsp->avg_no_rnd_vc1_chroma_pixels_tab[0]= ff_avg_vc1_chroma_mc8_ssse3_nornd;
+        dsp->put_no_rnd_vc1_chroma_pixels_tab[0] = ff_put_vc1_chroma_mc8_nornd_ssse3;
+        dsp->avg_no_rnd_vc1_chroma_pixels_tab[0] = ff_avg_vc1_chroma_mc8_nornd_ssse3;
     }
     if (mm_flags & AV_CPU_FLAG_SSE4) {
         dsp->vc1_h_loop_filter8  = ff_vc1_h_loop_filter8_sse4;
-- 
1.7.9.5

